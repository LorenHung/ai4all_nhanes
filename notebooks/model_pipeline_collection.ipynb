{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aca8b6d0-3e57-4977-a164-334293d56367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from  sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3266aac-4bcd-40e1-b706-9d8b1268fbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 29902 entries, 62161.0 to 93698.0\n",
      "Columns: 674 entries, SEQN to WHQ150\n",
      "dtypes: float64(672), object(2)\n",
      "memory usage: 154.0+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (600,601) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "all_data_df = pd.read_csv('all_data_df.csv')\n",
    "all_data_df.index = all_data_df['SEQN']\n",
    "all_data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b8fdf3-d6ef-4929-bf89-db5ef887b113",
   "metadata": {},
   "source": [
    "# Create Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e6a60f-069f-4f25-bc9c-0de4a07b6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select mental health screener columns and drop data that are empty\n",
    "mental_health_df = all_data_df.loc[:, 'DPQ010':'DPQ100'].dropna(how='all')\n",
    "all_data_df = all_data_df.loc[mental_health_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65f76f3-e741-402f-b689-eda66f9f1a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 15513 entries, 62161.0 to 93702.0\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   DPQ010  15513 non-null  object\n",
      " 1   DPQ020  15513 non-null  object\n",
      " 2   DPQ030  15513 non-null  object\n",
      " 3   DPQ040  15513 non-null  object\n",
      " 4   DPQ050  15513 non-null  object\n",
      " 5   DPQ060  15513 non-null  object\n",
      " 6   DPQ070  15513 non-null  object\n",
      " 7   DPQ080  15513 non-null  object\n",
      " 8   DPQ090  15513 non-null  object\n",
      " 9   DPQ100  15513 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "def mh(x):\n",
    "    if x == '\\.':\n",
    "        return 'missing'\n",
    "    elif x == 1:\n",
    "        return 'several days'\n",
    "    elif x == 2:\n",
    "        return 'more than half the days'\n",
    "    elif x == 3:\n",
    "        return 'nearly every day'\n",
    "    elif x == 7:\n",
    "        return 'refused'\n",
    "    elif x == 9:\n",
    "        return \"don't know\"\n",
    "    else:\n",
    "        return 'not at all'\n",
    "\n",
    "for col in mental_health_df.columns:\n",
    "    mental_health_df[col] = mental_health_df[col].apply(lambda x: mh(x))\n",
    "\n",
    "mental_health_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a8d265-8226-49df-a4d6-bdc45b26dec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc(row):\n",
    "    sum = 0\n",
    "    for i in ['DPQ010', 'DPQ020', 'DPQ030', 'DPQ040', \n",
    "              'DPQ050', 'DPQ060', 'DPQ070','DPQ080', \n",
    "              'DPQ090', 'DPQ100']:\n",
    "        if row[i] == 'several days':\n",
    "            sum += 1\n",
    "        if row[i] == 'more than half the days':\n",
    "            sum += 2\n",
    "        if row[i] == 'nearly every day':\n",
    "            sum += 3\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaba53ba-3a20-490a-a8b8-c58a29773b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 10 as threshold for depression\n",
    "mental_health_df['labels_raw'] = mental_health_df.apply(calc, axis=1)\n",
    "mental_health_df['labels'] = mental_health_df['labels_raw'].apply(lambda x: 1 if x >= 10 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0200e040-decf-4df4-9278-887191c8c765",
   "metadata": {},
   "source": [
    "# Select Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812fedf2-f062-40a2-a299-f69767ae9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    #diabetes\n",
    "    'DID040','DIQ160','DIQ170','DIQ172','DIQ175A','DIQ175B','DIQ175C',\n",
    "    'DIQ175D','DIQ175E','DIQ175F','DIQ175G','DIQ175H','DIQ175I','DIQ175J','DIQ175K',\n",
    "    'DIQ175L', 'DIQ175M','DIQ175N','DIQ175O','DIQ175P','DIQ175Q','DIQ175R','DIQ175S',\n",
    "    'DIQ175T','DIQ175U','DIQ175V','DIQ175W','DIQ180','DIQ050','DID060','DIQ060U',\n",
    "    'DIQ070','DIQ230','DIQ240','DID250','DID260','DIQ260U','DIQ275','DIQ280','DIQ291',\n",
    "    'DIQ300S','DIQ300D','DID310S','DID310D','DID320','DID330','DID341','DID350',\n",
    "    'DIQ350U','DIQ360','DIQ080', \n",
    "    #sleep disorder\n",
    "    'SEQN','SLQ050', \n",
    "    #physical activity\n",
    "    'PAQ605','PAQ610','PAD615','PAQ620','PAQ625','PAD630','PAQ635','PAQ640','PAD645',\n",
    "    'PAQ650','PAQ655','PAD660','PAQ665','PAQ670','PAD675','PAD680','PAQ706','PAQ710',\n",
    "    'PAQ715', \n",
    "    #weight history\n",
    "    'WHD010','WHD020','WHQ030','WHQ040','WHD050','WHQ060','WHQ070','WHD080A','WHD080B',\n",
    "    'WHD080C','WHD080D','WHD080E','WHD080F','WHD080G','WHD080H','WHD080I','WHD080J',\n",
    "    'WHD080K','WHD080M','WHD080N','WHD080O','WHD080P','WHD080Q','WHD080R','WHD080S',\n",
    "    'WHD080T','WHD080L','WHD110','WHD120','WHD130','WHD140','WHQ150', \n",
    "    #early childhood\n",
    "    'ECD010','ECQ020','ECD070A','ECD070B','ECQ080','ECQ090','WHQ030E','MCQ080E',\n",
    "    'ECQ150', \n",
    "    #alcohol issues\n",
    "    'ALQ101','ALQ110','ALQ120Q','ALQ120U','ALQ130','ALQ141Q','ALQ141U','ALQ151',\n",
    "    #early childhood\n",
    "    'ECD010','ECQ020','ECD070A','ECD070B','ECQ080','ECQ090','WHQ030E','MCQ080E','ECQ150', \n",
    "    #hospital access\n",
    "    'HUQ010','HUQ020','HUQ030','HUQ071','HUD080','HUQ090', \n",
    "    #health status\n",
    "    'HSD010','HSQ500','HSQ510','HSQ520','HSQ571','HSQ580','HSQ590','HSAQUEX',  \n",
    "    #income\n",
    "    'INQ012','INQ030','INQ060','INQ080','INQ090','INQ132','INQ140','INQ150',\n",
    "    'IND235','INDFMMPI','INDFMMPC', \n",
    "    #housing\n",
    "    'SEQN','HOD050','HOQ065', \n",
    "    #occupation\n",
    "    'OCD150','OCQ180','OCQ210','OCQ260','OCD270','OCQ380','OCD390G','OCD395', \n",
    "    #diet nutrition\n",
    "    'DBQ010','DBD030','DBD041','DBD050','DBD055','DBD061','DBQ073A','DBQ073B','DBQ073C',\n",
    "    'DBQ073D','DBQ073E','DBQ073U','DBQ700','DBQ197','DBQ223A','DBQ223B','DBQ223C',\n",
    "    'DBQ223D','DBQ223E','DBQ223U','DBQ229','DBQ235A','DBQ235B','DBQ235C','DBQ301',\n",
    "    'DBQ330','DBQ360','DBQ370','DBD381','DBQ390','DBQ400','DBD411','DBQ421','DBQ424',\n",
    "    'DBD895','DBD900','DBD905','DBD910', \n",
    "    #drug use\n",
    "    'DUQ200','DUQ210','DUQ211','DUQ213','DUQ215Q','DUQ215U','DUQ217','DUQ219','DUQ220Q',\n",
    "    'DUQ220U','DUQ230','DUQ240','DUQ250','DUQ260','DUQ270Q','DUQ270U','DUQ272','DUQ280',\n",
    "    'DUQ290','DUQ300','DUQ310Q','DUQ310U','DUQ320','DUQ330','DUQ340','DUQ350Q','DUQ350U',\n",
    "    'DUQ352','DUQ360','DUQ370','DUQ380A','DUQ380B','DUQ380C','DUQ380D','DUQ380E',\n",
    "    'DUQ390','DUQ400Q','DUQ400U','DUQ410','DUQ420', \n",
    "    \n",
    "]\n",
    "\n",
    "final_features = []\n",
    "\n",
    "for feature in features:\n",
    "    if feature not in final_features and feature != 'SEQN':\n",
    "        final_features.append(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315ce0fc-613d-4107-a471-aa83f17287e5",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea555645-dc80-422c-be6c-466fed3abe6d",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c12a5aef-b652-44e5-8cbe-d5ffaf502263",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data_df[final_features]\n",
    "y = mental_health_df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "929b38eb-da1e-4d0b-ba61-e4160a4ba91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ccfe6c-e2c1-4cf6-8352-866d8b36bace",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b26acaa-3dd8-4074-898d-7196c5ee252f",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295977d3",
   "metadata": {},
   "source": [
    "Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13ad0cdd-90ef-4193-9b42-64e131325d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
       "                ('enc', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
       "                ('red', PCA(n_components=10)),\n",
       "                ('clf',\n",
       "                 DummyClassifier(random_state=42, strategy='stratified'))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', DummyClassifier(strategy='stratified', random_state = 42))\n",
    "])\n",
    "dummy_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627449a3",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0082b1d-388d-4e81-a8fe-8f94d094d339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
       "                ('enc', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
       "                ('clf', LogisticRegression())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "lr_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11107b21",
   "metadata": {},
   "source": [
    "Linear Regression W/PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49e727c-0ee1-492c-aa23-42d051e9bc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
       "                ('enc', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
       "                ('red', PCA(n_components=10)), ('clf', LogisticRegression())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pca_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "lr_pca_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd39b8f",
   "metadata": {},
   "source": [
    "Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42f80f80-afee-406e-94f7-814029fb4084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
       "                ('enc', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
       "                ('red', PCA(n_components=10)),\n",
       "                ('clf', LinearDiscriminantAnalysis())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', LinearDiscriminantAnalysis())\n",
    "])\n",
    "lda_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954fb216",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68d871f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
       "                ('enc', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
       "                ('red', PCA(n_components=10)),\n",
       "                ('clf', DecisionTreeClassifier(random_state=42))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', DecisionTreeClassifier(random_state = 42))\n",
    "])\n",
    "dt_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13031308",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d454f28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
       "                ('enc', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
       "                ('red', PCA(n_components=10)),\n",
       "                ('clf',\n",
       "                 GradientBoostingClassifier(learning_rate=1.0, max_depth=1,\n",
       "                                            random_state=42))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdclass_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "                                       max_depth=1, random_state=42))\n",
    "])\n",
    "gdclass_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dc63db",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "efc75d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
       "                ('enc', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
       "                ('red', PCA(n_components=10)),\n",
       "                ('clf', RandomForestClassifier(max_depth=2, random_state=42))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclass_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', RandomForestClassifier(max_depth=2, random_state=42))\n",
    "])\n",
    "rfclass_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f2399",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b77e8063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
       "                ('enc', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
       "                ('red', PCA(n_components=10)), ('clf', GaussianNB())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "gnb_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc47e1",
   "metadata": {},
   "source": [
    "Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32e148e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
       "                ('enc', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
       "                ('red', PCA(n_components=10)),\n",
       "                ('clf', QuadraticDiscriminantAnalysis())])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('enc', OneHotEncoder(sparse=False, handle_unknown='ignore')), \n",
    "    ('red', PCA(n_components=10)),\n",
    "    ('clf', QuadraticDiscriminantAnalysis())\n",
    "])\n",
    "qda_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf50ec5-c191-4549-bc1e-6b068f468024",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b554495-2556-4de4-aa30-4d0486be4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_training_score = roc_auc_score(y_train.values, dummy_pipe.predict_proba(X_train)[:, 1])\n",
    "dummy_validation_score = roc_auc_score(y_val.values, dummy_pipe.predict_proba(X_val)[:, 1])\n",
    "\n",
    "lr_training_score = roc_auc_score(y_train.values, lr_pipe.predict_proba(X_train)[:, 1])\n",
    "lr_validation_score = roc_auc_score(y_val.values, lr_pipe.predict_proba(X_val)[:, 1])\n",
    "\n",
    "lr_pca_training_score = roc_auc_score(y_train.values, lr_pca_pipe.predict_proba(X_train)[:, 1])\n",
    "lr_pca_validation_score = roc_auc_score(y_val.values, lr_pca_pipe.predict_proba(X_val)[:, 1])\n",
    "\n",
    "lda_training_score = roc_auc_score(y_train.values, lda_pipe.predict_proba(X_train)[:, 1])\n",
    "lda_validation_score = roc_auc_score(y_val.values, lda_pipe.predict_proba(X_val)[:, 1])\n",
    "\n",
    "dt_training_score = roc_auc_score(y_train.values, dt_pipe.predict_proba(X_train)[:,1])\n",
    "dt_validation_score = roc_auc_score(y_val.values, dt_pipe.predict_proba(X_val)[:,1])\n",
    "\n",
    "gdclass_training_score = roc_auc_score(y_train.values, gdclass_pipe.predict_proba(X_train)[:,1])\n",
    "gdclass_validation_score = roc_auc_score(y_val.values, gdclass_pipe.predict_proba(X_val)[:,1])\n",
    "\n",
    "rfclass_training_score = roc_auc_score(y_train.values, rfclass_pipe.predict_proba(X_train)[:,1])\n",
    "rfclass_validation_score = roc_auc_score(y_val.values, rfclass_pipe.predict_proba(X_val)[:,1])\n",
    "\n",
    "gnb_training_score = roc_auc_score(y_train.values, gnb_pipe.predict_proba(X_train)[:,1])\n",
    "gnb_validation_score = roc_auc_score(y_val.values, gnb_pipe.predict_proba(X_val)[:,1])\n",
    "\n",
    "qda_training_score = roc_auc_score(y_train.values, qda_pipe.predict_proba(X_train)[:,1])\n",
    "qda_validation_score = roc_auc_score(y_val.values, qda_pipe.predict_proba(X_val)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47ba47c1-c365-4df3-8ebe-19dcaabe5f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training score</th>\n",
       "      <th>validation score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0.492412</td>\n",
       "      <td>0.488668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression</th>\n",
       "      <td>0.943031</td>\n",
       "      <td>0.778885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic regression pca</th>\n",
       "      <td>0.782618</td>\n",
       "      <td>0.786019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear discriminant analysis</th>\n",
       "      <td>0.782654</td>\n",
       "      <td>0.785655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree classifier</th>\n",
       "      <td>0.981097</td>\n",
       "      <td>0.586543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient boosting classifier</th>\n",
       "      <td>0.811593</td>\n",
       "      <td>0.774619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest classifier</th>\n",
       "      <td>0.773277</td>\n",
       "      <td>0.765059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaussian naive bayes</th>\n",
       "      <td>0.774812</td>\n",
       "      <td>0.783297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quadratic discriminat analysis</th>\n",
       "      <td>0.769659</td>\n",
       "      <td>0.761393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                training score  validation score\n",
       "dummy                                 0.492412          0.488668\n",
       "logistic regression                   0.943031          0.778885\n",
       "logistic regression pca               0.782618          0.786019\n",
       "linear discriminant analysis          0.782654          0.785655\n",
       "decision tree classifier              0.981097          0.586543\n",
       "gradient boosting classifier          0.811593          0.774619\n",
       "random forest classifier              0.773277          0.765059\n",
       "gaussian naive bayes                  0.774812          0.783297\n",
       "quadratic discriminat analysis        0.769659          0.761393"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'dummy': {\n",
    "            'training score': dummy_training_score,\n",
    "            'validation score': dummy_validation_score\n",
    "        },\n",
    "        'logistic regression': {\n",
    "            'training score': lr_training_score,\n",
    "            'validation score': lr_validation_score\n",
    "        },\n",
    "        'logistic regression pca': {\n",
    "            'training score': lr_pca_training_score,\n",
    "            'validation score': lr_pca_validation_score\n",
    "        },\n",
    "        'linear discriminant analysis': {\n",
    "            'training score': lda_training_score,\n",
    "            'validation score': lda_validation_score\n",
    "        },\n",
    "        'decision tree classifier': {\n",
    "            'training score': dt_training_score,\n",
    "            'validation score': dt_validation_score\n",
    "        },\n",
    "        'gradient boosting classifier': {\n",
    "            'training score': gdclass_training_score,\n",
    "            'validation score': gdclass_validation_score\n",
    "        },\n",
    "        'random forest classifier': {\n",
    "            'training score': rfclass_training_score,\n",
    "            'validation score': rfclass_validation_score\n",
    "        },\n",
    "        'gaussian naive bayes': {\n",
    "            'training score': gnb_training_score,\n",
    "            'validation score': gnb_validation_score\n",
    "        },\n",
    "        'quadratic discriminat analysis': {\n",
    "            'training score': qda_training_score,\n",
    "            'validation score': qda_validation_score\n",
    "        }\n",
    "    \n",
    "    }, \n",
    "    orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b098e-2fc8-4567-b989-529233391605",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602ecf0d-5893-4bc4-bb20-d0fcea8581d4",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/permutation_importance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9ce389f-4094-4cc9-b4ee-f3f3fc335ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(\n",
    "    lr_pca_pipe, \n",
    "    X_val, \n",
    "    y_val,\n",
    "    n_repeats=10,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7e53e41-0072-4f06-954b-692afdd652a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'importance_means': r['importances_mean'],\n",
    "        'importances_std': r['importances_std']\n",
    "    }, orient='columns'\n",
    ")\n",
    "feature_importances.index = X_val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80e52b06-d814-4296-a9c1-07d330cef749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance_means</th>\n",
       "      <th>importances_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DUQ219</th>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUQ213</th>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUQ272</th>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIQ170</th>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.000413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUQ270Q</th>\n",
       "      <td>0.001547</td>\n",
       "      <td>0.000316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHQ040</th>\n",
       "      <td>-0.000516</td>\n",
       "      <td>0.001032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALQ130</th>\n",
       "      <td>-0.000580</td>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHQ030</th>\n",
       "      <td>-0.000709</td>\n",
       "      <td>0.001304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INQ140</th>\n",
       "      <td>-0.000709</td>\n",
       "      <td>0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHQ070</th>\n",
       "      <td>-0.000967</td>\n",
       "      <td>0.000661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         importance_means  importances_std\n",
       "DUQ219           0.001934         0.000408\n",
       "DUQ213           0.001934         0.000645\n",
       "DUQ272           0.001741         0.000295\n",
       "DIQ170           0.001741         0.000413\n",
       "DUQ270Q          0.001547         0.000316\n",
       "...                   ...              ...\n",
       "WHQ040          -0.000516         0.001032\n",
       "ALQ130          -0.000580         0.000193\n",
       "WHQ030          -0.000709         0.001304\n",
       "INQ140          -0.000709         0.001017\n",
       "WHQ070          -0.000967         0.000661\n",
       "\n",
       "[233 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.sort_values('importance_means', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc042e-d41c-4f4d-85fd-f0f33c6a79d8",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3cc5c6-454f-4ce0-a2c9-59992ce9aa81",
   "metadata": {},
   "source": [
    "- https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "- https://medium.com/@kocur4d/hyper-parameter-tuning-with-pipelines-5310aff069d6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19502c92-3fef-4f5f-83f4-d3d9814a090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {\n",
    "  'clf__solver': ['newton-cg', 'lbfgs'],\n",
    "  'clf__penalty': ['none', 'l1'],  \n",
    "  'clf__C': [100, 10],  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "031520d9-f25c-4eab-8a73-2e644f46bcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/pipeline.py\", line 346, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Volumes/Active/GitHub/ai4all_nhanes/env/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lr_pca_pipe, \n",
    "    param_grid=grid_params, \n",
    "    n_jobs=-1, \n",
    "    cv=cv, \n",
    "    scoring='roc_auc',\n",
    "    error_score=0\n",
    ")\n",
    "grid_result = grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b76132af-e42f-4ba3-978a-10f2c812fb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7800530446103456"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "55fef325-1ea8-4ac9-b1f4-089ae2a9192a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__C': 10, 'clf__penalty': 'none', 'clf__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ea38f7f-2bb3-4ce1-9eba-f050266ec3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf55afe-d095-4d42-9348-35306170191a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
